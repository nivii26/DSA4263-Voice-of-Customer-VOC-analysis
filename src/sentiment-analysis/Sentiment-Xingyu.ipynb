{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfbf1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import sklearn.metrics\n",
    "import nltk\n",
    "import nlpaug.augmenter.word as naw\n",
    "import numpy as np\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76592b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b700947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from scipy.stats import uniform\n",
    "from scipy import interp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score,precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f4bd1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load the data from the csv file\n",
    "train_data = pd.read_csv(\"reviews.csv\")\n",
    "# train_label = train_data[\"Sentiment\"]\n",
    "original_data = pd.DataFrame(train_data[\"Text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81f173c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to preprocess the text data\n",
    "def preprocess_text(text):\n",
    "    # convert to lowercase\n",
    "    text = text.lower()\n",
    "    # remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-z]', ' ', text)\n",
    "    # tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    # remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    tokens= ' '.join(tokens)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "# remove the html symbol\n",
    "def remove_html(text):\n",
    "    regex = r\"<[^>]+>\"\n",
    "    text_new = re.sub(regex, \" \", text)\n",
    "    return text_new\n",
    "\n",
    "# apply the preprocessing function to the text data\n",
    "train_data['Text'] = train_data['Text'].apply(remove_html)\n",
    "train_data['Text'] = train_data['Text'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3afbad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define an NLPAug data augmentation function\n",
    "def augment_text(text):\n",
    "    # define an augmentation method\n",
    "    aug = naw.SynonymAug(aug_src='wordnet', lang='eng')\n",
    "    # apply the augmentation method to the text\n",
    "    augmented_text = aug.augment(text)\n",
    "    return augmented_text\n",
    "\n",
    "# apply the augmentation function to the preprocessed text data\n",
    "train_data['Text'] = train_data['Text'].apply(augment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582e8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# over sampling\n",
    "ros = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "X = train_data['Text'].values.reshape(-1, 1)\n",
    "y = train_data['Sentiment']\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "train_data = pd.DataFrame({'Text': X_resampled.ravel(), 'Sentiment': y_resampled})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d4e3a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the data to a new csv file\n",
    "train_data.to_csv(\"oversampling_reviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ad767",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dddaad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Word2Vec model on the preprocessed text data\n",
    "word2vec_model = Word2Vec(train_data['Text'], min_count=1)\n",
    "\n",
    "# create a function to generate the word embedding vectors for each sentence\n",
    "def generate_word_embedding(sentence):\n",
    "    # initialize an empty array for the sentence vector\n",
    "    sentence_vector = []\n",
    "    # loop through each word in the sentence\n",
    "    for word in sentence:\n",
    "        try:\n",
    "            # add the vector representation of the word to the sentence vector\n",
    "            word_vector = word2vec_model.wv[word]\n",
    "            sentence_vector.append(word_vector)\n",
    "        except KeyError:\n",
    "            # ignore words that are not in the vocabulary\n",
    "            pass\n",
    "    # take the mean of the word vectors to get the sentence vector\n",
    "    sentence_vector = np.mean(sentence_vector, axis=0)\n",
    "    return sentence_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cae1851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the generate_word_embedding() function to the preprocessed text data\n",
    "train_data['embedding'] = train_data['Text'].apply(generate_word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4182170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new DataFrame for the feature matrix\n",
    "embedding_size = word2vec_model.vector_size\n",
    "features_df = pd.DataFrame(train_data['embedding'].tolist(), columns=[f'embedding_{i}' for i in range(embedding_size)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f68399ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform PCA with n_components set to retain 98% of variance\n",
    "pca_emb = PCA(n_components=0.98)\n",
    "features_emb_pca = pca_emb.fit_transform(features_df)\n",
    "\n",
    "# create a new DataFrame for the PCA features\n",
    "pca_emb_cols = [f\"PC_emb{i+1}\" for i in range(features_emb_pca.shape[1])]\n",
    "pca_df_emb = pd.DataFrame(features_emb_pca, columns=pca_emb_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f61c32f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a TF-IDF vectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# fit and transform the vectorizer on the preprocessed text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(train_data['Text'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_features_df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d889571",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## standardize the features\n",
    "#scaler = StandardScaler()\n",
    "#features_std = scaler.fit_transform(features)\n",
    "\n",
    "# perform PCA with n_components set to retain 95% of variance\n",
    "pca = PCA(n_components=0.95)\n",
    "features_tfidf_pca = pca.fit_transform(tfidf_features_df)\n",
    "\n",
    "# create a new DataFrame for the PCA features\n",
    "pca_tfidf_cols = [f\"PC_tfidf{i+1}\" for i in range(features_tfidf_pca.shape[1])]\n",
    "pca_df_tfidf = pd.DataFrame(features_tfidf_pca, columns=pca_tfidf_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba292c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the TF-IDF features to the feature matrix DataFrame\n",
    "features_df = pd.concat([pca_df_tfidf, pca_df_emb], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c78cb80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the number of characters, number of words, and number of capital characters as features\n",
    "features_df['num_characters'] = train_data['Text'].apply(lambda x: len(' '.join(x)))\n",
    "features_df['num_words'] = train_data['Text'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c5e6f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the common features from the features.csv file\n",
    "features_df['num_sentences'] = original_data[\"Text\"].apply(lambda s: s.count('.'))\n",
    "features_df['num_question_marks'] = original_data[\"Text\"].apply(lambda s: s.count('?'))\n",
    "features_df['num_exclamation_marks'] = original_data[\"Text\"].apply(lambda s: s.count('!'))\n",
    "features_df['num_unique_words'] = train_data[\"Text\"].apply(lambda x: len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0130108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the label column to the feature matrix DataFrame\n",
    "label = features_df.columns\n",
    "features_df['Sentiment'] = train_data['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03d06370",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# weight the negative sentiment samples by 1.5\n",
    "features_df.loc[features_df['Sentiment'] == 'negative',label] *= 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2017a940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_tfidf1</th>\n",
       "      <th>PC_tfidf2</th>\n",
       "      <th>PC_tfidf3</th>\n",
       "      <th>PC_tfidf4</th>\n",
       "      <th>PC_tfidf5</th>\n",
       "      <th>PC_tfidf6</th>\n",
       "      <th>PC_tfidf7</th>\n",
       "      <th>PC_tfidf8</th>\n",
       "      <th>PC_tfidf9</th>\n",
       "      <th>PC_tfidf10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_emb96</th>\n",
       "      <th>PC_emb97</th>\n",
       "      <th>PC_emb98</th>\n",
       "      <th>num_characters</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_sentences</th>\n",
       "      <th>num_question_marks</th>\n",
       "      <th>num_exclamation_marks</th>\n",
       "      <th>num_unique_words</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.071812</td>\n",
       "      <td>0.036136</td>\n",
       "      <td>0.076162</td>\n",
       "      <td>0.058094</td>\n",
       "      <td>0.015693</td>\n",
       "      <td>-0.068980</td>\n",
       "      <td>-0.009392</td>\n",
       "      <td>0.050062</td>\n",
       "      <td>-0.086675</td>\n",
       "      <td>-0.005748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007832</td>\n",
       "      <td>-0.004934</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.130083</td>\n",
       "      <td>0.064077</td>\n",
       "      <td>0.186264</td>\n",
       "      <td>0.178121</td>\n",
       "      <td>0.043476</td>\n",
       "      <td>-0.063714</td>\n",
       "      <td>0.012203</td>\n",
       "      <td>0.060614</td>\n",
       "      <td>-0.090439</td>\n",
       "      <td>0.010428</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>-0.003294</td>\n",
       "      <td>-0.003709</td>\n",
       "      <td>232</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.090828</td>\n",
       "      <td>0.038738</td>\n",
       "      <td>0.086590</td>\n",
       "      <td>0.030063</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.020041</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.236875</td>\n",
       "      <td>-0.103662</td>\n",
       "      <td>-0.137266</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002308</td>\n",
       "      <td>0.007702</td>\n",
       "      <td>-0.007528</td>\n",
       "      <td>541</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.032244</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.016679</td>\n",
       "      <td>-0.011835</td>\n",
       "      <td>-0.005652</td>\n",
       "      <td>-0.009966</td>\n",
       "      <td>0.012565</td>\n",
       "      <td>0.031322</td>\n",
       "      <td>-0.033928</td>\n",
       "      <td>-0.066652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>0.003852</td>\n",
       "      <td>311</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.051115</td>\n",
       "      <td>-0.117562</td>\n",
       "      <td>0.050717</td>\n",
       "      <td>-0.013965</td>\n",
       "      <td>-0.013435</td>\n",
       "      <td>-0.031462</td>\n",
       "      <td>-0.059974</td>\n",
       "      <td>0.022282</td>\n",
       "      <td>0.005212</td>\n",
       "      <td>0.054587</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007418</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.007445</td>\n",
       "      <td>216</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3444 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PC_tfidf1  PC_tfidf2  PC_tfidf3  PC_tfidf4  PC_tfidf5  PC_tfidf6  \\\n",
       "0  -0.071812   0.036136   0.076162   0.058094   0.015693  -0.068980   \n",
       "1  -0.130083   0.064077   0.186264   0.178121   0.043476  -0.063714   \n",
       "2  -0.090828   0.038738   0.086590   0.030063   0.018296   0.020041   \n",
       "3  -0.032244   0.003467   0.016679  -0.011835  -0.005652  -0.009966   \n",
       "4   0.051115  -0.117562   0.050717  -0.013965  -0.013435  -0.031462   \n",
       "\n",
       "   PC_tfidf7  PC_tfidf8  PC_tfidf9  PC_tfidf10  ...  PC_emb96  PC_emb97  \\\n",
       "0  -0.009392   0.050062  -0.086675   -0.005748  ... -0.007832 -0.004934   \n",
       "1   0.012203   0.060614  -0.090439    0.010428  ...  0.008681 -0.003294   \n",
       "2   0.000002   0.236875  -0.103662   -0.137266  ... -0.002308  0.007702   \n",
       "3   0.012565   0.031322  -0.033928   -0.066652  ... -0.001196 -0.003016   \n",
       "4  -0.059974   0.022282   0.005212    0.054587  ...  0.007418  0.000506   \n",
       "\n",
       "   PC_emb98  num_characters  num_words  num_sentences  num_question_marks  \\\n",
       "0  0.000907              98          1            4.0                 0.0   \n",
       "1 -0.003709             232          1            4.0                 0.0   \n",
       "2 -0.007528             541          1            9.0                 0.0   \n",
       "3  0.003852             311          1            3.0                 0.0   \n",
       "4  0.007445             216          1            4.0                 0.0   \n",
       "\n",
       "   num_exclamation_marks  num_unique_words  Sentiment  \n",
       "0                    0.0                 1   positive  \n",
       "1                    0.0                 1   positive  \n",
       "2                    0.0                 1   positive  \n",
       "3                    2.0                 1   positive  \n",
       "4                    1.0                 1   positive  \n",
       "\n",
       "[5 rows x 3444 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the feature matrix to a CSV file\n",
    "# pca_df_emb.to_csv(\"pca_df_emb.csv\", index=False)\n",
    "# pca_df_tfidf.to_csv(\"pca_df_tfidf.csv\", index=False)\n",
    "#features_df.to_csv(\"features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51a5678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_tfidf1</th>\n",
       "      <th>PC_tfidf2</th>\n",
       "      <th>PC_tfidf3</th>\n",
       "      <th>PC_tfidf4</th>\n",
       "      <th>PC_tfidf5</th>\n",
       "      <th>PC_tfidf6</th>\n",
       "      <th>PC_tfidf7</th>\n",
       "      <th>PC_tfidf8</th>\n",
       "      <th>PC_tfidf9</th>\n",
       "      <th>PC_tfidf10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_tfidf2554</th>\n",
       "      <th>PC_tfidf2555</th>\n",
       "      <th>PC_tfidf2556</th>\n",
       "      <th>PC_tfidf2557</th>\n",
       "      <th>PC_tfidf2558</th>\n",
       "      <th>PC_tfidf2559</th>\n",
       "      <th>PC_tfidf2560</th>\n",
       "      <th>PC_emb1</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125620</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>0.047654</td>\n",
       "      <td>-0.053766</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.057737</td>\n",
       "      <td>0.058247</td>\n",
       "      <td>-0.071434</td>\n",
       "      <td>-0.030766</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014703</td>\n",
       "      <td>-0.006541</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>-0.003647</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>-0.010708</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.604965</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042603</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>-0.059601</td>\n",
       "      <td>0.039494</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>-0.108345</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011572</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.017747</td>\n",
       "      <td>-0.023063</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>-0.559065</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.034431</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>-0.002671</td>\n",
       "      <td>-0.044581</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.012137</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.023059</td>\n",
       "      <td>-0.016890</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>-0.793231</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043434</td>\n",
       "      <td>-0.051018</td>\n",
       "      <td>0.289668</td>\n",
       "      <td>0.091026</td>\n",
       "      <td>-0.011638</td>\n",
       "      <td>0.069017</td>\n",
       "      <td>-0.082393</td>\n",
       "      <td>-0.098824</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013448</td>\n",
       "      <td>-0.030621</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>-0.004246</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>-0.010947</td>\n",
       "      <td>0.266332</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.056289</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>-0.029635</td>\n",
       "      <td>0.055384</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>-0.057992</td>\n",
       "      <td>-0.012327</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>-0.023922</td>\n",
       "      <td>0.024825</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007892</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>-0.008579</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.008741</td>\n",
       "      <td>-0.111557</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PC_tfidf1  PC_tfidf2  PC_tfidf3  PC_tfidf4  PC_tfidf5  PC_tfidf6  \\\n",
       "0   0.125620   0.086304   0.047654  -0.053766   0.016895   0.006636   \n",
       "1  -0.042603   0.000193   0.029059  -0.059601   0.039494  -0.034193   \n",
       "2  -0.034431   0.010012  -0.002671  -0.044581   0.023652  -0.001375   \n",
       "3   0.043434  -0.051018   0.289668   0.091026  -0.011638   0.069017   \n",
       "4  -0.056289   0.006874  -0.029635   0.055384   0.078201  -0.057992   \n",
       "\n",
       "   PC_tfidf7  PC_tfidf8  PC_tfidf9  PC_tfidf10  ...  PC_tfidf2554  \\\n",
       "0   0.057737   0.058247  -0.071434   -0.030766  ...     -0.014703   \n",
       "1  -0.002060  -0.108345   0.023581    0.000313  ...     -0.011572   \n",
       "2  -0.012137   0.003543   0.012075    0.002073  ...     -0.001365   \n",
       "3  -0.082393  -0.098824   0.048846    0.005609  ...     -0.013448   \n",
       "4  -0.012327   0.003309  -0.023922    0.024825  ...     -0.007892   \n",
       "\n",
       "   PC_tfidf2555  PC_tfidf2556  PC_tfidf2557  PC_tfidf2558  PC_tfidf2559  \\\n",
       "0     -0.006541      0.001270     -0.003647      0.001165     -0.010708   \n",
       "1     -0.001005     -0.017747     -0.023063      0.016968      0.004904   \n",
       "2     -0.001086     -0.023059     -0.016890      0.004170     -0.000059   \n",
       "3     -0.030621      0.013245      0.006127     -0.004246     -0.032258   \n",
       "4      0.000735      0.006927     -0.008579      0.009152      0.012545   \n",
       "\n",
       "   PC_tfidf2560   PC_emb1  Sentiment  tag  \n",
       "0      0.001703  0.604965   positive    1  \n",
       "1      0.006062 -0.559065   positive    1  \n",
       "2      0.002757 -0.793231   positive    1  \n",
       "3     -0.010947  0.266332   positive    1  \n",
       "4     -0.008741 -0.111557   positive    1  \n",
       "\n",
       "[5 rows x 2563 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=pd.read_csv(\"features_train.csv\")\n",
    "train_data['tag'] = train_data['Sentiment'].map(dict(positive=1, negative=0))\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd132dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_tfidf1</th>\n",
       "      <th>PC_tfidf2</th>\n",
       "      <th>PC_tfidf3</th>\n",
       "      <th>PC_tfidf4</th>\n",
       "      <th>PC_tfidf5</th>\n",
       "      <th>PC_tfidf6</th>\n",
       "      <th>PC_tfidf7</th>\n",
       "      <th>PC_tfidf8</th>\n",
       "      <th>PC_tfidf9</th>\n",
       "      <th>PC_tfidf10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_tfidf2554</th>\n",
       "      <th>PC_tfidf2555</th>\n",
       "      <th>PC_tfidf2556</th>\n",
       "      <th>PC_tfidf2557</th>\n",
       "      <th>PC_tfidf2558</th>\n",
       "      <th>PC_tfidf2559</th>\n",
       "      <th>PC_tfidf2560</th>\n",
       "      <th>PC_emb1</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003003</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>-0.024751</td>\n",
       "      <td>-0.008711</td>\n",
       "      <td>0.048035</td>\n",
       "      <td>0.080845</td>\n",
       "      <td>0.019316</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>-0.019494</td>\n",
       "      <td>-0.001264</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004350</td>\n",
       "      <td>-0.003682</td>\n",
       "      <td>-0.012045</td>\n",
       "      <td>-0.008119</td>\n",
       "      <td>-0.002653</td>\n",
       "      <td>-0.013525</td>\n",
       "      <td>-0.008150</td>\n",
       "      <td>0.293276</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.016410</td>\n",
       "      <td>-0.038728</td>\n",
       "      <td>0.026165</td>\n",
       "      <td>0.052852</td>\n",
       "      <td>0.075277</td>\n",
       "      <td>0.048377</td>\n",
       "      <td>-0.014616</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>0.018016</td>\n",
       "      <td>-0.063928</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010688</td>\n",
       "      <td>-0.014109</td>\n",
       "      <td>-0.017873</td>\n",
       "      <td>0.003445</td>\n",
       "      <td>0.010449</td>\n",
       "      <td>0.003113</td>\n",
       "      <td>-0.013101</td>\n",
       "      <td>0.530278</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.024891</td>\n",
       "      <td>0.015307</td>\n",
       "      <td>-0.025498</td>\n",
       "      <td>-0.047200</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.032510</td>\n",
       "      <td>0.038903</td>\n",
       "      <td>0.027520</td>\n",
       "      <td>0.126051</td>\n",
       "      <td>-0.172537</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011773</td>\n",
       "      <td>-0.004405</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>0.004289</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.004968</td>\n",
       "      <td>0.561678</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.020077</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>-0.009455</td>\n",
       "      <td>-0.019804</td>\n",
       "      <td>-0.004952</td>\n",
       "      <td>0.032510</td>\n",
       "      <td>-0.005290</td>\n",
       "      <td>-0.004231</td>\n",
       "      <td>0.018715</td>\n",
       "      <td>-0.004419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015926</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>-0.002900</td>\n",
       "      <td>-0.002967</td>\n",
       "      <td>-0.003947</td>\n",
       "      <td>0.013005</td>\n",
       "      <td>0.012213</td>\n",
       "      <td>-0.219977</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.032384</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>-0.005000</td>\n",
       "      <td>-0.041640</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>0.040683</td>\n",
       "      <td>-0.012633</td>\n",
       "      <td>-0.010550</td>\n",
       "      <td>-0.003390</td>\n",
       "      <td>0.012361</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001538</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>-0.015470</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>-0.013583</td>\n",
       "      <td>0.209119</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PC_tfidf1  PC_tfidf2  PC_tfidf3  PC_tfidf4  PC_tfidf5  PC_tfidf6  \\\n",
       "0   0.003003  -0.007670  -0.024751  -0.008711   0.048035   0.080845   \n",
       "1   0.016410  -0.038728   0.026165   0.052852   0.075277   0.048377   \n",
       "2  -0.024891   0.015307  -0.025498  -0.047200   0.110320   0.032510   \n",
       "3  -0.020077   0.006177  -0.009455  -0.019804  -0.004952   0.032510   \n",
       "4  -0.032384   0.010378  -0.005000  -0.041640   0.010491   0.040683   \n",
       "\n",
       "   PC_tfidf7  PC_tfidf8  PC_tfidf9  PC_tfidf10  ...  PC_tfidf2554  \\\n",
       "0   0.019316  -0.005109  -0.019494   -0.001264  ...     -0.004350   \n",
       "1  -0.014616   0.008187   0.018016   -0.063928  ...     -0.010688   \n",
       "2   0.038903   0.027520   0.126051   -0.172537  ...     -0.011773   \n",
       "3  -0.005290  -0.004231   0.018715   -0.004419  ...     -0.015926   \n",
       "4  -0.012633  -0.010550  -0.003390    0.012361  ...     -0.001538   \n",
       "\n",
       "   PC_tfidf2555  PC_tfidf2556  PC_tfidf2557  PC_tfidf2558  PC_tfidf2559  \\\n",
       "0     -0.003682     -0.012045     -0.008119     -0.002653     -0.013525   \n",
       "1     -0.014109     -0.017873      0.003445      0.010449      0.003113   \n",
       "2     -0.004405      0.000392      0.006039      0.004289      0.001587   \n",
       "3      0.002942     -0.002900     -0.002967     -0.003947      0.013005   \n",
       "4      0.008185      0.000329      0.001891     -0.015470      0.000781   \n",
       "\n",
       "   PC_tfidf2560   PC_emb1  Sentiment  tag  \n",
       "0     -0.008150  0.293276   positive    1  \n",
       "1     -0.013101  0.530278   positive    1  \n",
       "2      0.004968  0.561678   positive    1  \n",
       "3      0.012213 -0.219977   positive    1  \n",
       "4     -0.013583  0.209119   positive    1  \n",
       "\n",
       "[5 rows x 2563 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data=pd.read_csv(\"features_test.csv\")\n",
    "test_data['tag'] = test_data['Sentiment'].map(dict(positive=1, negative=0))\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0173e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def result(predictions,actual):\n",
    "    print(\"F1 score: \", f1_score(actual, predictions))\n",
    "print(\"PR_AUC score: \", average_precision_score(actual, predictions))\n",
    "print(\"ROC_AUC score: \", roc_auc_score(actual, predictions))\n",
    "print(\"Accuracy: \", accuracy_score(actual, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f116cd8e",
   "metadata": {},
   "source": [
    "## XGBOOST\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63f82948",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "442c01f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=train_data.iloc[: , :-2]\n",
    "y_train=train_data['tag']\n",
    "X_test=test_data.iloc[: , :-2]\n",
    "y_test=test_data['tag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "765c9be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC_tfidf1</th>\n",
       "      <th>PC_tfidf2</th>\n",
       "      <th>PC_tfidf3</th>\n",
       "      <th>PC_tfidf4</th>\n",
       "      <th>PC_tfidf5</th>\n",
       "      <th>PC_tfidf6</th>\n",
       "      <th>PC_tfidf7</th>\n",
       "      <th>PC_tfidf8</th>\n",
       "      <th>PC_tfidf9</th>\n",
       "      <th>PC_tfidf10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC_tfidf2552</th>\n",
       "      <th>PC_tfidf2553</th>\n",
       "      <th>PC_tfidf2554</th>\n",
       "      <th>PC_tfidf2555</th>\n",
       "      <th>PC_tfidf2556</th>\n",
       "      <th>PC_tfidf2557</th>\n",
       "      <th>PC_tfidf2558</th>\n",
       "      <th>PC_tfidf2559</th>\n",
       "      <th>PC_tfidf2560</th>\n",
       "      <th>PC_emb1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.125620</td>\n",
       "      <td>0.086304</td>\n",
       "      <td>0.047654</td>\n",
       "      <td>-0.053766</td>\n",
       "      <td>0.016895</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.057737</td>\n",
       "      <td>0.058247</td>\n",
       "      <td>-0.071434</td>\n",
       "      <td>-0.030766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>0.012494</td>\n",
       "      <td>-0.014703</td>\n",
       "      <td>-0.006541</td>\n",
       "      <td>0.001270</td>\n",
       "      <td>-0.003647</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>-0.010708</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.604965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.042603</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>-0.059601</td>\n",
       "      <td>0.039494</td>\n",
       "      <td>-0.034193</td>\n",
       "      <td>-0.002060</td>\n",
       "      <td>-0.108345</td>\n",
       "      <td>0.023581</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013434</td>\n",
       "      <td>0.012414</td>\n",
       "      <td>-0.011572</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.017747</td>\n",
       "      <td>-0.023063</td>\n",
       "      <td>0.016968</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.006062</td>\n",
       "      <td>-0.559065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.034431</td>\n",
       "      <td>0.010012</td>\n",
       "      <td>-0.002671</td>\n",
       "      <td>-0.044581</td>\n",
       "      <td>0.023652</td>\n",
       "      <td>-0.001375</td>\n",
       "      <td>-0.012137</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016966</td>\n",
       "      <td>0.026854</td>\n",
       "      <td>-0.001365</td>\n",
       "      <td>-0.001086</td>\n",
       "      <td>-0.023059</td>\n",
       "      <td>-0.016890</td>\n",
       "      <td>0.004170</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.002757</td>\n",
       "      <td>-0.793231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.043434</td>\n",
       "      <td>-0.051018</td>\n",
       "      <td>0.289668</td>\n",
       "      <td>0.091026</td>\n",
       "      <td>-0.011638</td>\n",
       "      <td>0.069017</td>\n",
       "      <td>-0.082393</td>\n",
       "      <td>-0.098824</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.005609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010654</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>-0.013448</td>\n",
       "      <td>-0.030621</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.006127</td>\n",
       "      <td>-0.004246</td>\n",
       "      <td>-0.032258</td>\n",
       "      <td>-0.010947</td>\n",
       "      <td>0.266332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.056289</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>-0.029635</td>\n",
       "      <td>0.055384</td>\n",
       "      <td>0.078201</td>\n",
       "      <td>-0.057992</td>\n",
       "      <td>-0.012327</td>\n",
       "      <td>0.003309</td>\n",
       "      <td>-0.023922</td>\n",
       "      <td>0.024825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005712</td>\n",
       "      <td>-0.006714</td>\n",
       "      <td>-0.007892</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>-0.008579</td>\n",
       "      <td>0.009152</td>\n",
       "      <td>0.012545</td>\n",
       "      <td>-0.008741</td>\n",
       "      <td>-0.111557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2561 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PC_tfidf1  PC_tfidf2  PC_tfidf3  PC_tfidf4  PC_tfidf5  PC_tfidf6  \\\n",
       "0   0.125620   0.086304   0.047654  -0.053766   0.016895   0.006636   \n",
       "1  -0.042603   0.000193   0.029059  -0.059601   0.039494  -0.034193   \n",
       "2  -0.034431   0.010012  -0.002671  -0.044581   0.023652  -0.001375   \n",
       "3   0.043434  -0.051018   0.289668   0.091026  -0.011638   0.069017   \n",
       "4  -0.056289   0.006874  -0.029635   0.055384   0.078201  -0.057992   \n",
       "\n",
       "   PC_tfidf7  PC_tfidf8  PC_tfidf9  PC_tfidf10  ...  PC_tfidf2552  \\\n",
       "0   0.057737   0.058247  -0.071434   -0.030766  ...      0.005929   \n",
       "1  -0.002060  -0.108345   0.023581    0.000313  ...      0.013434   \n",
       "2  -0.012137   0.003543   0.012075    0.002073  ...      0.016966   \n",
       "3  -0.082393  -0.098824   0.048846    0.005609  ...      0.010654   \n",
       "4  -0.012327   0.003309  -0.023922    0.024825  ...      0.005712   \n",
       "\n",
       "   PC_tfidf2553  PC_tfidf2554  PC_tfidf2555  PC_tfidf2556  PC_tfidf2557  \\\n",
       "0      0.012494     -0.014703     -0.006541      0.001270     -0.003647   \n",
       "1      0.012414     -0.011572     -0.001005     -0.017747     -0.023063   \n",
       "2      0.026854     -0.001365     -0.001086     -0.023059     -0.016890   \n",
       "3      0.010035     -0.013448     -0.030621      0.013245      0.006127   \n",
       "4     -0.006714     -0.007892      0.000735      0.006927     -0.008579   \n",
       "\n",
       "   PC_tfidf2558  PC_tfidf2559  PC_tfidf2560   PC_emb1  \n",
       "0      0.001165     -0.010708      0.001703  0.604965  \n",
       "1      0.016968      0.004904      0.006062 -0.559065  \n",
       "2      0.004170     -0.000059      0.002757 -0.793231  \n",
       "3     -0.004246     -0.032258     -0.010947  0.266332  \n",
       "4      0.009152      0.012545     -0.008741 -0.111557  \n",
       "\n",
       "[5 rows x 2561 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b56077dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomSearchCV\n",
    "# define the parameters to tune\n",
    "param_dist = {\"learning_rate\": uniform(0, 2),\n",
    "              \"gamma\": uniform(1, 0.000001),\n",
    "              \"max_depth\": range(1,50),\n",
    "              \"n_estimators\": range(1,300),\n",
    "              \"min_child_weight\": range(1,10),\n",
    "              'n_jobs': range(1,5)}\n",
    "#instance of RandomSearchCV\n",
    "rs = RandomizedSearchCV(XGBClassifier(), param_distributions=param_dist, n_iter=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90bad1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           callbacks=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           early_stopping_rounds=None,\n",
       "                                           enable_categorical=False,\n",
       "                                           eval_metric=None, gamma=None,\n",
       "                                           gpu_id=None, grow_policy=None,\n",
       "                                           importance_type=None,\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None, max_bin=None,\n",
       "                                           max_c...\n",
       "                                           predictor=None, random_state=None,\n",
       "                                           reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=3,\n",
       "                   param_distributions={'gamma': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7feddd82a8b0>,\n",
       "                                        'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7feddd682670>,\n",
       "                                        'max_depth': range(1, 50),\n",
       "                                        'min_child_weight': range(1, 10),\n",
       "                                        'n_estimators': range(1, 300),\n",
       "                                        'n_jobs': range(1, 5)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "444b9ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=rs.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92245039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9545634136704859\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00e49e5",
   "metadata": {},
   "source": [
    "## Ramdon Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a191ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b760732",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "parameters = {\n",
    "    'n_estimators': [5,50,100],\n",
    "    'max_depth': [2,10,20,None]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(rf,parameters)\n",
    "cv.fit(X_train, y_train)\n",
    "y_preds=cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc4769ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8729241877256317\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfddbd30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
